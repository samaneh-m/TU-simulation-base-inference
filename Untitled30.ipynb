{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samaneh-m/TU-simulation-base-inference/blob/main/Untitled30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"bayesflow>=2.0\"\n",
        "!pip install tensorflow  # CPU version is fine; GPU optional"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L4RBQIcd_FN",
        "outputId": "a5b6e218-a699-4a1d-f0eb-019c1fc2e7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesflow>=2.0 in /usr/local/lib/python3.11/dist-packages (2.0.5)\n",
            "Requirement already satisfied: keras>=3.9 in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (3.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (1.15.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bayesflow>=2.0) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.9->bayesflow>=2.0) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bayesflow>=2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->bayesflow>=2.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->bayesflow>=2.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->bayesflow>=2.0) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.9->bayesflow>=2.0) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.9->bayesflow>=2.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.9->bayesflow>=2.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.9->bayesflow>=2.0) (0.1.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import bayesflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UpBEkJEeDV1",
        "outputId": "150ff91d-1615-4257-8c06-743027992f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:bayesflow:Using backend 'tensorflow'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import bayesflow as bf\n",
        "\n",
        "from bayesflow.types import Shape\n",
        "from bayesflow.utils import tree_concatenate\n",
        "from bayesflow.utils.decorators import allow_batch_size"
      ],
      "metadata": {
        "id": "SCXqj6RHdDyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HiddenStateSimulator:\n",
        "    def __init__(self, seq_len=50):\n",
        "        self.seq_len = seq_len\n",
        "        self.states = ['alpha', 'other']\n",
        "        self.amino_acids = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
        "                            'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "\n",
        "        # Emission probabilities\n",
        "        self.emissions = {\n",
        "            'alpha': np.array([\n",
        "                12, 6, 3, 5, 1, 9, 5, 4, 2, 7,\n",
        "                12, 6, 3, 4, 2, 5, 4, 1, 3, 6\n",
        "            ]) / 100,\n",
        "            'other': np.array([\n",
        "                6, 5, 5, 6, 2, 5, 3, 9, 3, 5,\n",
        "                8, 6, 2, 4, 6, 7, 6, 1, 4, 7\n",
        "            ]) / 100\n",
        "        }\n",
        "\n",
        "        # Transition matrix: rows are from-states, columns are to-states\n",
        "        self.transitions = {\n",
        "            'alpha': {'alpha': 0.90, 'other': 0.10},\n",
        "            'other': {'alpha': 0.05, 'other': 0.95}\n",
        "        }\n",
        "\n",
        "    def sample(self, batch_shape=1):\n",
        "        samples = []\n",
        "        states = []\n",
        "\n",
        "        for _ in range(batch_shape):\n",
        "            seq = []\n",
        "            st_seq = []\n",
        "\n",
        "            current_state = 'other'\n",
        "            for _ in range(self.seq_len):\n",
        "                # Emit amino acid\n",
        "                probs = self.emissions[current_state]\n",
        "                aa = np.random.choice(self.amino_acids, p=probs)\n",
        "                seq.append(aa)\n",
        "                st_seq.append(current_state)\n",
        "\n",
        "                # Transition to next state\n",
        "                next_state = np.random.choice(self.states, p=[\n",
        "                    self.transitions[current_state]['alpha'],\n",
        "                    self.transitions[current_state]['other']\n",
        "                ])\n",
        "                current_state = next_state\n",
        "\n",
        "            samples.append(seq)\n",
        "            states.append(st_seq)\n",
        "\n",
        "        return {\n",
        "            'observed_sequence': samples,\n",
        "            'hidden_states': states\n",
        "        }"
      ],
      "metadata": {
        "id": "iaDV95WJTKSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim = HiddenStateSimulator(seq_len=50)\n",
        "data = sim.sample(batch_shape=1000)\n",
        "\n",
        "print(\"Amino acid sequence:\")\n",
        "print(data['observed_sequence'][0])\n",
        "print(\"\\nHidden states:\")\n",
        "print(data['hidden_states'][0])\n",
        "# len(data['observed_sequence'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Unz3aSVNoT",
        "outputId": "9bb46279-9955-491e-a60d-f25543b0b041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amino acid sequence:\n",
            "['S', 'S', 'L', 'D', 'T', 'A', 'C', 'N', 'S', 'P', 'S', 'V', 'Q', 'K', 'Y', 'T', 'P', 'P', 'F', 'G', 'A', 'P', 'G', 'K', 'C', 'K', 'Q', 'E', 'P', 'I', 'R', 'L', 'P', 'T', 'D', 'V', 'T', 'S', 'V', 'L', 'A', 'Y', 'D', 'F', 'A', 'L', 'R', 'F', 'R', 'L']\n",
            "\n",
            "Hidden states:\n",
            "['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'alpha', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mapping data\n",
        "Mapping our data to make it suitable for BayesFlow algorithm.\n",
        "We need to map the amino acids into numbers (0,19) and also the states (0,1)"
      ],
      "metadata": {
        "id": "S4qa2kIAbAUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map amino acids to integers (0 to 19)\n",
        "amino_acids = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
        "               'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "\n",
        "# Map states to integers\n",
        "state_to_int = {'alpha': 1, 'other': 0}"
      ],
      "metadata": {
        "id": "gv2bn3LCZX2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sequences(data):\n",
        "    x_encoded = [[aa_to_int[aa] for aa in seq] for seq in data['observed_sequence']]\n",
        "    theta_encoded = [[state_to_int[state] for state in seq] for seq in data['hidden_states']]\n",
        "    return np.array(x_encoded), np.array(theta_encoded)\n",
        "\n",
        "x_train, theta_train = encode_sequences(data)"
      ],
      "metadata": {
        "id": "wY2uLiRKbYUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x_train_onehot = to_categorical(x_train, num_classes=20)  # shape: (N, seq_len, 20)"
      ],
      "metadata": {
        "id": "pBhKUzSobdYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, seq_len, AA = x_train_onehot.shape\n",
        "\n",
        "# 3. Define a simple simulator that draws from your pre-simulated data\n",
        "def replay_simulator(batch_size):\n",
        "    idx = np.random.choice(N, size=batch_size, replace=False)\n",
        "    return {\"hidden_states\": theta_train[idx]}, {\"observations\": x_train_onehot[idx]}\n",
        "\n",
        "# 4. Create summary and inference (coupling flow) networks\n",
        "summary_net = bf.networks.TimeSeriesNetwork(\n",
        "    input_shape=(seq_len, AA),\n",
        "    summary_variables=[\"observations\"],\n",
        "    layers=[128, 64],\n",
        "    rnn_units=64\n",
        ")\n",
        "\n",
        "inference_net = bf.networks.CouplingFlow(\n",
        "    n_parameters=seq_len,\n",
        "    context_summary=[\"observations\"],\n",
        "    coupling_layers=6,\n",
        "    hidden_sizes=[128, 128]\n",
        ")"
      ],
      "metadata": {
        "id": "f8MhJSCf6JnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplaySimulator:\n",
        "    def __init__(self, x_data, theta_data):\n",
        "        self.x = x_data\n",
        "        self.theta = theta_data\n",
        "        self.n = theta_data.shape[0]\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        idx = np.random.choice(self.n, size=batch_size, replace=False)\n",
        "        return {\n",
        "            \"hidden_states\": self.theta[idx],\n",
        "            \"observations\": self.x[idx]}"
      ],
      "metadata": {
        "id": "zaINydWGgSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulator = ReplaySimulator(x_train_onehot, theta_train)"
      ],
      "metadata": {
        "id": "48ooC3t4gZG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = bf.BasicWorkflow(\n",
        "    inference_network=inference_net,\n",
        "    summary_network=summary_net,\n",
        "    inference_variables=[\"hidden_states\"],\n",
        "    summary_variables=[\"observations\"],\n",
        "    simulator=simulator\n",
        ")"
      ],
      "metadata": {
        "id": "WGUc7oUwgbY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = workflow.fit_online(\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    num_batches_per_epoch=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGkicOu-gfXY",
        "outputId": "93a4cd67-d4f8-42ac-e5a9-f8743727c493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
            "INFO:bayesflow:Building on a test batch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 149ms/step - loss: 30.9250\n",
            "Epoch 2/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 167ms/step - loss: -25.7514\n",
            "Epoch 3/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 143ms/step - loss: -45.2053\n",
            "Epoch 4/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 147ms/step - loss: -57.5122\n",
            "Epoch 5/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 147ms/step - loss: -68.2395\n",
            "Epoch 6/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 142ms/step - loss: -77.1832\n",
            "Epoch 7/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 141ms/step - loss: -87.0690\n",
            "Epoch 8/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 143ms/step - loss: -93.8766\n",
            "Epoch 9/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 148ms/step - loss: -100.8535\n",
            "Epoch 10/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 143ms/step - loss: -103.2089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Making posterior predictions\n",
        "Making posterior predictions to evaluate the model."
      ],
      "metadata": {
        "id": "shcNwBW34_z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Ensure tf is imported if not already\n",
        "\n",
        "# Assuming 'workflow' is your trained BayesFlow workflow\n",
        "# and 'x_train_onehot', 'theta_train' are your encoded data from earlier\n",
        "\n",
        "# 1. Generate some new, unseen data for evaluation\n",
        "num_test_sequences = 100\n",
        "test_indices = np.random.choice(N, size=num_test_sequences, replace=False)\n",
        "\n",
        "x_test_observations = x_train_onehot[test_indices]\n",
        "theta_test_true = theta_train[test_indices]\n",
        "\n",
        "# Prepare the data in the format expected by the summary network\n",
        "# This is still a dictionary, as the summary network is designed to handle this.\n",
        "test_data_for_summary = {\"observations\": tf.constant(x_test_observations, dtype=tf.float32)}\n",
        "\n",
        "# --- CORRECTED PART ---\n",
        "# 2. Get the summarized context from the summary network\n",
        "#    The summary network takes the dictionary input and outputs a single tensor.\n",
        "#    You need to explicitly call the summary network on your test observations.\n",
        "summarized_context = workflow.summary_network(test_data_for_summary)\n",
        "\n",
        "# 3. Perform posterior inference using the trained inference_network\n",
        "#    Now, `conditions` will be the actual tensor output by the summary network.\n",
        "posterior_samples_raw = workflow.inference_network.sample(\n",
        "    conditions=summarized_context, # Pass the tensor output from the summary network\n",
        "    batch_shape=500 # Number of samples to draw for each condition\n",
        ")\n",
        "\n",
        "# posterior_samples_raw will be a dictionary, e.g., {'hidden_states': ...}\n",
        "posterior_samples = posterior_samples_raw # Keep the variable name consistent\n",
        "\n",
        "print(f\"Shape of posterior samples: {posterior_samples['hidden_states'].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "48WAzFBCMkeY",
        "outputId": "91bc3c90-75bf-41b7-9ceb-7b41e4c7e991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mThe structure of `inputs` doesn't match the expected structure.\nExpected: keras_tensor\nReceived: inputs={'observations': 'Tensor(shape=(100, 50, 20))'}\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs={'observations': 'tf.Tensor(shape=(100, 50, 20), dtype=float32)'}\n  • training=False\n  • mask={'observations': 'None'}\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-70-958265255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#    The summary network takes the dictionary input and outputs a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#    You need to explicitly call the summary network on your test observations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msummarized_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_for_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# 3. Perform posterior inference using the trained inference_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bayesflow/networks/time_series_network/time_series_network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_projector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mThe structure of `inputs` doesn't match the expected structure.\nExpected: keras_tensor\nReceived: inputs={'observations': 'Tensor(shape=(100, 50, 20))'}\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs={'observations': 'tf.Tensor(shape=(100, 50, 20), dtype=float32)'}\n  • training=False\n  • mask={'observations': 'None'}\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate a new test sample\n",
        "test_sample = sim.sample(batch_shape=1)\n",
        "x_test, theta_test = encode_sequences(test_sample)\n",
        "x_test_onehot = to_categorical(x_test, num_classes=20)\n",
        "\n",
        "# 2. Compute summary features using the summary network\n",
        "summaries = summary_net(x_test_onehot)\n",
        "\n",
        "# 3. Sample from the posterior using the inference network directly\n",
        "posterior_samples = workflow.sample(\n",
        "    batch_size=1,\n",
        "    n_samples=100,\n",
        "    observed={\"observations\": x_test_onehot}\n",
        ")\n",
        "\n",
        "# 4. Shape: (n_samples, seq_len)\n",
        "posterior_array = posterior_samples[\"hidden_states\"]\n",
        "\n",
        "# 5. Estimate posterior probabilities (P(alpha-helix) = mean over samples)\n",
        "posterior_probs = np.mean(posterior_array, axis=0)\n",
        "\n",
        "# 6. Convert to hard predictions\n",
        "predicted_states = (posterior_probs >= 0.5).astype(int)\n",
        "true_states = theta_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "7Q6IGDuhGMOE",
        "outputId": "227f8dc1-b843-41dd-df31-f2e7f39680e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "BasicWorkflow.sample() missing 2 required keyword-only arguments: 'num_samples' and 'conditions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-66-130112114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 3. Sample from the posterior using the inference network directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m posterior_samples = workflow.sample(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BasicWorkflow.sample() missing 2 required keyword-only arguments: 'num_samples' and 'conditions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use first sample for now\n",
        "true_hidden_states = np.array([1 if s == 'alpha' else 0 for s in data['hidden_states'][0]])"
      ],
      "metadata": {
        "id": "x7d8TKL3Djcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}